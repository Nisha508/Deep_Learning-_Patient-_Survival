{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ef89e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.20.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (23.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (1.2.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (4.62.3)\n",
      "Requirement already satisfied: numba in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (0.54.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hp\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from numba->shap) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from numba->shap) (0.37.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4befcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                            classification_report,\n",
    "                            roc_auc_score, roc_curve, auc, precision_recall_curve,\n",
    "                            confusion_matrix)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"D:\\panda\\Patient_DL1.csv\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7931e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1650258",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.isnull().sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1147eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows with missing values:\", raw_data.isnull().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d348aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_missing = raw_data.isnull().sum(axis=0).sort_values(ascending=False)[raw_data.isnull().sum(axis=0).sort_values(ascending=False) > 25000]\n",
    "\n",
    "print(\"\\nTotal features with more than\", 25000, \"missing values:\", len(large_missing))\n",
    "\n",
    "raw_data.drop(large_missing.index.tolist() + ['encounter_id', 'hospital_admit_source', 'icu_admit_source', 'icu_id', 'icu_stay_type', 'patient_id', 'hospital_id', 'readmission_status'], \n",
    "              axis=1,\n",
    "             inplace = True)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbaa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data[['bmi', 'weight', 'height']].isna().sum(axis=1) == 0]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1493c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data[['age','gender','hospital_death','bmi']].dropna(): This selects the columns 'age', 'gender', 'hospital_death', and 'bmi' from the DataFrame 'raw_data'. \n",
    "#By removing any rows with missing values using 'dropna()'. This ensures that only complete data is used for plotting.\n",
    "# color=\"gender\": This sets the 'gender' column as the grouping variable, allowing the histogram to display separate distributions for different genders using different colors.\n",
    "# marginal=\"box\": This adds a box plot along the margins of the histogram, providing a visual summary of the distribution of 'age' (on the x-axis) and 'hospital_death' (on the y-axis) for each gender group.\n",
    "# hover_data=raw_data[['age','gender','hospital_death','bmi']].columns: This specifies that when hovering over a data point in the histogram, the values for all columns in the selected subset ('age', 'gender', 'hospital_death', and 'bmi') will be displayed as tooltips.\n",
    "fig = px.histogram(raw_data[['age','gender','hospital_death','bmi']].dropna(), x=\"age\", y=\"hospital_death\", color=\"gender\",\n",
    "                   marginal=\"box\", # or violin, rug\n",
    "                   hover_data=raw_data[['age','gender','hospital_death','bmi']].columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code filters the DataFrame 'raw_data' to select only the rows where the 'gender' column is equal to 'F' (representing females).\n",
    "# From the filtered DataFrame, it selects only the columns 'age' and 'hospital_death'.\n",
    "# It groups the resulting DataFrame by the 'age' column. This means that the data will be aggregated based on unique age values.\n",
    "# It calculates the mean of the 'hospital_death' column for each age group. \n",
    "# It resets the index of the resulting DataFrame. After grouping, the 'age' column becomes the index. \n",
    "age_death_F=raw_data[raw_data['gender']=='F'][['age','hospital_death']].groupby('age').mean().reset_index()\n",
    "age_death_M=raw_data[raw_data['gender']=='M'][['age','hospital_death']].groupby('age').mean().reset_index()\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots()\n",
    "# `fig.add_trace(go.Scatter(x=age_death_F['age'], y=age_death_F['hospital_death'], name=\"Female patients\"))`\n",
    "#   - Adds a scatter plot to the figure using the `go.Scatter` object.\n",
    "#   - `x=age_death_F['age']`: Sets the x-axis values to the 'age' column from the `age_death_F` DataFrame (representing female patients).\n",
    "#   - `y=age_death_F['hospital_death']`: Sets the y-axis values to the 'hospital_death' column from the `age_death_F` DataFrame.\n",
    "#   - `name=\"Female patients\"`: Assigns a name to the trace for legend display.\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=age_death_F['age'], y=age_death_F['hospital_death'], name=\"Female patients\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=age_death_M['age'], y=age_death_M['hospital_death'],name=\"Male patients\"))\n",
    "fig.update_layout(\n",
    "    title_text=\"<b>Average hospital death probability of patients<b>\")\n",
    "fig.update_xaxes(title_text=\"<b>patient age<b>\")\n",
    "#   - `secondary_y=False` indicates that this is the primary y-axis (in case you have multiple y-axes).\n",
    "fig.update_yaxes(title_text=\"<b>Average Hospital Death</b>\", secondary_y=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa84eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df=raw_data[['weight','hospital_death','bmi']]\n",
    "weight_df['weight']=weight_df['weight'].round(0)\n",
    "# This line of code rounds the values in the 'bmi' column of the DataFrame 'weight_df' to the nearest whole number (0 decimal places).\n",
    "weight_df['bmi']=weight_df['bmi'].round(0)\n",
    "weight_death=weight_df[['weight','hospital_death']].groupby('weight').mean().reset_index()\n",
    "bmi_death=weight_df[['bmi','hospital_death']].groupby('bmi').mean().reset_index()\n",
    "fig = make_subplots(rows=1, cols=1, shared_yaxes=True)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=weight_death['weight'], y=weight_death['hospital_death'], name=\"Weight\"),\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=bmi_death['bmi'], y=bmi_death['hospital_death'], name=\"BMI\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=\"<b>impacts of BMI and weight over patients<b>\"\n",
    ")\n",
    "fig.update_yaxes(title_text=\"<b>Average Hospital Death\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICU_type=raw_data[['icu_type','age','hospital_death']]\n",
    "# The purpose of this replacement is likely to consolidate similar ICU types under a common label, \n",
    "#potentially for better analysis or visualization. \n",
    "ICU_type['icu_type']=ICU_type['icu_type'].replace({'CTICU':'CCU-CTICU',\n",
    "                                              'Cardiac ICU':'CCT-CTICU',\n",
    "                                              'CTICU':'CCT-CTICU',\n",
    "                                              'CSICU':'SICU'})\n",
    "#ICU_type['pre_icu_los_days']=ICU_type['pre_icu_los_days'].round(0)\n",
    "ICU_df=ICU_type.groupby(['icu_type','age']).mean().reset_index()\n",
    "# This line calculates the count of occurrences for each combination of 'icu_type' and 'age', and \n",
    "#assigns these counts to a new column named 'count' in the 'ICU_df' DataFrame.\n",
    "ICU_df['count']=ICU_type.groupby(['icu_type','age']).count().reset_index()['hospital_death']\n",
    "\n",
    "# This line creates a scatter plot using Plotly Express, where:\n",
    "\n",
    "# x=\"age\": Sets the x-axis to represent the 'age' column.\n",
    "# y=\"hospital_death\": Sets the y-axis to represent the mean 'hospital_death' values calculated earlier.\n",
    "# size=\"count\": Scales the size of each data point based on the count of occurrences for that group.\n",
    "# color=\"icu_type\": Assigns different colors to data points based on their 'icu_type'.\n",
    "# hover_name=\"icu_type\": Displays the 'icu_type' when hovering over a data point.\n",
    "# log_x=False: Disables logarithmic scaling for the x-axis.\n",
    "# size_max=60: Sets the maximum size of the data points.\n",
    "\n",
    "fig = px.scatter(ICU_df, x=\"age\", y=\"hospital_death\", size=\"count\", color=\"icu_type\",\n",
    "           hover_name=\"icu_type\", log_x=False, size_max=60,)\n",
    "fig.update_layout(\n",
    "    title_text=\"<b>Survival rate at different types of ICU<b>\"\n",
    ")\n",
    "fig.update_yaxes(title_text=\"<b>Average Hospital Death<b>\")\n",
    "fig.update_xaxes(title_text=\"<b>Age<b>\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef27358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet focuses on analyzing the relationship between patient age, \n",
    "#the APACHE III body system, and hospital death. \n",
    "\n",
    "# 1. Selection: It selects three columns from the 'raw_data' DataFrame: 'age', 'apache_3j_bodysystem', and 'hospital_death'.\n",
    "#These columns are relevant for investigating how age and the affected body system might be associated with hospital death.\n",
    "\n",
    "# 2. Grouping and Aggregation: It groups the selected data by 'apache_3j_bodysystem' and 'age'. \n",
    "#For each combination of body system and age, it calculates two aggregate values:\n",
    "#     - 'size': The number of patients within that group.\n",
    "#     - 'mean': The average hospital death rate for patients in that group.\n",
    "\n",
    "# 3. Resetting Index: It resets the index of the resulting DataFrame. This makes the 'apache_3j_bodysystem' and 'age' columns\n",
    "#regular data columns instead of index levels, facilitating further analysis or visualization.\n",
    "\n",
    "# In summary, this code prepares the data to explore how the probability of hospital death varies across \n",
    "#different age groups and affected body systems as defined by APACHE III.\n",
    "apache3=raw_data[['age','apache_3j_bodysystem','hospital_death']]\n",
    "apache3=apache3.groupby(['apache_3j_bodysystem','age']).agg(['size','mean']).reset_index()\n",
    "# Calculate size and mean of 'hospital_death' for each 'apache_3j_bodysystem'\n",
    "apache3['size']=apache3['hospital_death']['size']\n",
    "apache3['mean']=apache3['hospital_death']['mean']\n",
    "# Remove the original 'hospital_death' column as it's now represented by 'size' and 'mean'\n",
    "apache3.drop('hospital_death',axis=1,inplace=True)\n",
    "# Extract unique body systems\n",
    "systems =list(apache3['apache_3j_bodysystem'].unique())\n",
    "\n",
    "\n",
    "# Step 1: Iterate through Systems\n",
    "# The code iterates through each element ('s') in the list 'systems'. 'n' keeps track of the index of the current element.\n",
    "\n",
    "# Step 2: Create Visibility List\n",
    "# For each system, it creates a list called 'visible' filled with False values, equal in length to the number of systems. \n",
    "# Then, it sets the element at index 'n' to True. This is done to control the visibility of traces in a plot later on.\n",
    "\n",
    "# Step 3: Build Update Dictionary\n",
    "# A dictionary 'temp_dict' is created to define an update for a plot. It includes:\n",
    "#    - 'label': A string representation of the current system ('s').\n",
    "#    - 'method': Set to 'update', indicating that this dictionary will update an existing plot.\n",
    "#    - 'args': A list of arguments for the update. It contains two dictionaries:\n",
    "#        - The first dictionary sets the 'visible' attribute of traces based on the 'visible' list created earlier.\n",
    "#        - The second dictionary sets the title of the plot to the current system ('s') in bold.\n",
    "\n",
    "# Step 4: Append to Update List\n",
    "# The 'temp_dict' is appended to a list called 'list_updatemenus'. This list will store all the update dictionaries \n",
    "#for the plot.\n",
    "\n",
    "# Step 5: Create Masks (Outside the Loop)\n",
    "# After the loop, the code iterates through 'systems' again. For each system 's', it creates a boolean mask called 'mask'.\n",
    "# The mask is likely used to filter data based on the 'apache_3j_bodysystem' column in a DataFrame called 'apache3'. \n",
    "# The exact filtering logic is not shown in the provided code snippet.\n",
    "\n",
    "# In Summary\n",
    "# This code snippet is part of a larger process that creates an interactive plot where users can select \n",
    "#different systems to view. \n",
    "# The 'list_updatemenus' will be used to create dropdown menus or buttons to control the visibility of traces \n",
    "#based on the selected system. \n",
    "# The masks are likely used to filter data for each system, allowing the plot to display relevant information \n",
    "#for the chosen system.\n",
    "\n",
    "\n",
    "data = []\n",
    "list_updatemenus = []\n",
    "for n, s in enumerate(systems):\n",
    "    visible = [False] * len(systems)\n",
    "    visible[n] = True\n",
    "    temp_dict = dict(label = str(s),\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': visible},\n",
    "                         {'title': '<b>'+s+'<b>'}])\n",
    "    list_updatemenus.append(temp_dict)\n",
    "    \n",
    "\n",
    "for s in systems:\n",
    "    mask = (apache3['apache_3j_bodysystem'].values == s) \n",
    "    trace = (dict(visible = False,     \n",
    "        x = apache3.loc[mask, 'age'],\n",
    "        y = apache3.loc[mask, 'mean'],\n",
    "        mode = 'markers',\n",
    "        marker = {'size':apache3.loc[mask, 'size']/apache3.loc[mask,'size'].sum()*1000,\n",
    "                 'color':apache3.loc[mask, 'mean'],\n",
    "                 'showscale': True})\n",
    "                   )\n",
    "    data.append(trace)\n",
    "\n",
    "data[0]['visible'] = True    \n",
    "    \n",
    "layout = dict(updatemenus=list([dict(buttons= list_updatemenus)]),\n",
    "              xaxis=dict(title = '<b>Age<b>', range=[min(apache3.loc[:, 'age'])-10, max(apache3.loc[:, 'age']) + 10]),\n",
    "              yaxis=dict(title = '<b>Average Hospital Death<b>', range=[min(apache3.loc[:, 'mean'])-0.1, max(apache3.loc[:, 'mean'])+0.1]),\n",
    "              title='<b>Survival Rate<b>' )\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='update_dropdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cat = [\n",
    " 'elective_surgery',\n",
    " 'apache_post_operative',\n",
    " 'arf_apache',\n",
    " 'gcs_unable_apache',\n",
    " 'intubated_apache',\n",
    " 'ventilated_apache',\n",
    " 'aids',\n",
    " 'cirrhosis',\n",
    " 'diabetes_mellitus',\n",
    " 'hepatic_failure',\n",
    " 'immunosuppression',\n",
    " 'leukemia',\n",
    " 'lymphoma',\n",
    " 'solid_tumor_with_metastasis']\n",
    "\n",
    "categorical = ['ethnicity',\n",
    " 'gender',\n",
    " 'icu_type',\n",
    " 'apache_3j_bodysystem',\n",
    " 'apache_2_bodysystem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4da82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code identifies the columns in the DataFrame 'raw_data' that have only two unique values.\n",
    "raw_data.nunique()[raw_data.nunique() == 2].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.select_dtypes(include='O').columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dacb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_numeric = raw_data[numerical_cat + categorical + ['hospital_death']].columns.tolist()\n",
    "numeric_only = raw_data.drop(not_numeric,axis=1).columns.tolist()\n",
    "numeric_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cat:\n",
    "    raw_data[col] = raw_data[col].astype('Int64')\n",
    "\n",
    "for col in numerical_cat:\n",
    "    raw_data[col] = raw_data[col].fillna(raw_data[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line calculates the number of missing values for each column in the DataFrame 'raw_data[numeric_only]' and sorts the result in ascending order.\n",
    "# It then filters this sorted result to select only the columns with less than 11000 missing values.\n",
    "# Finally, it extracts the names of these columns into a list called 'split_one'.\n",
    "split_one = raw_data[numeric_only].isna().sum(axis=0).sort_values()[raw_data[numeric_only].isna().sum(axis=0) < 11000].index.tolist()\n",
    "split_two = raw_data[numeric_only].isna().sum(axis=0).sort_values()[raw_data[numeric_only].isna().sum(axis=0) > 11000].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc20ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the current column with the mean of that column\n",
    "for col in split_two:\n",
    "    raw_data[col] = raw_data[col].fillna(raw_data[col].mean())\n",
    "# Drop rows with any remaining missing values from 'raw_data' and store in 'process_data'\n",
    "process_data = raw_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data[categorical].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b2a89",
   "metadata": {},
   "source": [
    "# using one-hot encoder because of large range of unique values in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code creates dummy variables for the categorical features in the 'process_data' DataFrame.\n",
    "# pd.get_dummies(): This function is used to convert categorical variables into a set of binary (0 or 1) variables, one for each unique category.\n",
    "# prefix='isin': This sets the prefix for the newly created dummy variable column names to 'isin'. This helps to identify the origin of these columns.\n",
    "# prefix_sep='_': This sets the separator between the prefix ('isin') and the original category name in the dummy variable column names.\n",
    "# columns=categorical: This specifies the list of categorical columns in 'process_data' for which dummy variables should be created.\n",
    "# drop_first=False: This indicates that the first dummy variable for each categorical feature should not be dropped. By default, \n",
    "#'pd.get_dummies' drops the first dummy variable to avoid multicollinearity, but in this case, all dummy variables are kept.\n",
    "icu_data = pd.get_dummies(process_data,\n",
    "    prefix='isin',\n",
    "    prefix_sep='_',\n",
    "    columns=categorical,\n",
    "    drop_first=False)\n",
    "# This line of code resets the index of the 'icu_data' DataFrame and drops the original index.\n",
    "# reset_index(drop=True): This method resets the index to a default integer index (0, 1, 2, ...) and \n",
    "#removes the original index.\n",
    "# inplace=True: This modifies the 'icu_data' DataFrame directly without creating a copy.\n",
    "icu_data.reset_index(drop = True, inplace = True)\n",
    "icu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code iterates through each column name in the DataFrame 'icu_data' and \n",
    "#converts it to lowercase using a list comprehension. \n",
    "# The resulting list of lowercase column names is then assigned back to 'icu_data.columns', effectively renaming \n",
    "#all columns to lowercase.\n",
    "icu_data.columns = [x.lower() for x in icu_data.columns.tolist()]\n",
    "# This line of code removes duplicate columns from the DataFrame 'icu_data'. \n",
    "# It uses the loc accessor to select all rows and only the non-duplicate columns. \n",
    "# The ~ operator inverts the boolean mask returned by 'icu_data.columns.duplicated()', \n",
    "#selecting the columns that are not duplicates.\n",
    "icu_data = icu_data.loc[:,~icu_data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code assigns the data type of the 'arf_apache' column in the 'icu_data' DataFrame to the variable 't'. \n",
    "# This essentially stores the information about what kind of values are present in the 'arf_apache' column, \n",
    "#such as integers, floating-point numbers, strings, etc.\n",
    "\n",
    "t = icu_data['arf_apache'].dtype\n",
    "\n",
    "# This code iterates through each column ('col') in the 'icu_data' DataFrame. \n",
    "# For each column, it checks if its data type is either 'uint8' (unsigned 8-bit integer) or the same as the data type \n",
    "#stored in the variable 't' (which represents the data type of the 'arf_apache' column).\n",
    "# If either condition is true, it converts the data type of that column to 'int' (integer). \n",
    "#This is likely done to ensure consistency in data types across the DataFrame, especially if the columns with 'uint8' or the same data type as 'arf_apache' are meant to represent numerical values.\n",
    "for col in tqdm(icu_data.columns.tolist()):\n",
    "    if icu_data[col].values.dtype == 'uint8' or t == icu_data[col].values.dtype:\n",
    "        icu_data[col] = icu_data[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88161a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = icu_data.drop(['hospital_death'], axis=1)\n",
    "y = icu_data['hospital_death']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,\n",
    "                                                    random_state=11,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f740303",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd385cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(X_train, y_train, X_test, y_test, **kwargs):#     - `**kwargs`: Keyword arguments to control model selection.\n",
    "    scores = {}\n",
    "    models = []\n",
    "    if 'xgb' in kwargs.keys() and kwargs['xgb']:\n",
    "        #if the keyword argument 'xgb' is present and set to True. If so, it proceeds to train an XGBoost model.\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train._get_numeric_data(), np.ravel(y_train, order='C'))\n",
    "        # extracts the numerical features from the training data.\n",
    "        #np.ravel(y_train, order='C'-------------This flattens the target labels into a 1D array.\n",
    "        y_pred = xgb.predict(X_test._get_numeric_data())\n",
    "        scores['xgb']= [accuracy_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]\n",
    "#         scores['xgb']['roc_auc'] = roc_auc_score(y_test, y_pred)\n",
    "        models.append(xgb)\n",
    "\n",
    "    if 'rf' in kwargs.keys() and kwargs['rf']:\n",
    "        rf = RandomForestClassifier(n_estimators=200)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        scores['rf']= [accuracy_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]\n",
    "#         scores['rf']['roc_auc'] = roc_auc_score(y_test, y_pred)\n",
    "        models.append(rf)\n",
    "\n",
    "    if 'extree' in kwargs.keys() and kwargs['extree']:\n",
    "        extree = ExtraTreesClassifier()\n",
    "        extree.fit(X_train, y_train)\n",
    "        y_pred = extree.predict(X_test)\n",
    "        scores['extree'] = [accuracy_score(y_test, y_pred), roc_auc_score(y_test, y_pred)]\n",
    "#         scores['extree']['roc_auc'] = roc_auc_score(y_test, y_pred)\n",
    "        models.append(extree)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling(X_train,y_train, X_test, y_test, xgb=True, rf=True, extree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b70120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - `model`: The trained machine learning model.\n",
    "# - `y_test`: The true labels of the test data.\n",
    "# - `y_hat`: The predicted labels from the model.\n",
    "def model_performance(model, y_test, y_hat) :\n",
    "    conf_matrix = confusion_matrix(y_test, y_hat)\n",
    "    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n",
    "                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2,\n",
    "                        colorscale = 'Viridis', showscale  = False)\n",
    "\n",
    "    #Show metrics\n",
    "    tp = conf_matrix[1,1]\n",
    "    fn = conf_matrix[1,0]\n",
    "    fp = conf_matrix[0,1]\n",
    "    tn = conf_matrix[0,0]\n",
    "   # Accuracy:\n",
    "#   - Calculated as (tp + tn) / (tp + tn + fp + fn)\n",
    "#   - Represents the proportion of correctly classified instances \n",
    "#(both true positives and true negatives) out of all instances.\n",
    "\n",
    "# Precision:\n",
    "#   - Calculated as tp / (tp + fp)\n",
    "#   - Represents the proportion of true positive predictions out of all positive predictions made by the model.\n",
    "#   - Focuses on minimizing false positives (incorrectly predicting positive when it's actually negative).\n",
    "\n",
    "# Recall (Sensitivity):\n",
    "#   - Calculated as tp / (tp + fn)\n",
    "#   - Represents the proportion of true positive predictions out of all actual positive instances.\n",
    "#   - Focuses on minimizing false negatives (incorrectly predicting negative when it's actually positive).\n",
    "\n",
    "# F1-score:\n",
    "#   - Calculated as 2 * ((precision * recall) / (precision + recall))\n",
    "#   - Provides a harmonic mean between precision and recall, balancing both metrics.\n",
    "#   - Useful when there's an uneven class distribution or when both false positives and false negatives are important to consider.\n",
    "    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n",
    "    Precision =  (tp/(tp+fp))\n",
    "    Recall    =  (tp/(tp+fn))\n",
    "    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n",
    "\n",
    "    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n",
    "    show_metrics = show_metrics.T\n",
    "\n",
    "    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n",
    "    # trace2: This part of the code is responsible for creating a bar chart visualization of the calculated performance metrics (Accuracy, Precision, Recall, and F1-score).\n",
    "\n",
    "# go.Bar: This indicates that we are using the Bar chart object from the Plotly Graph Objects library to create the visualization.\n",
    "\n",
    "# x = (show_metrics[0].values): This assigns the actual metric values from the 'show_metrics' DataFrame to the x-axis \n",
    "#of the bar chart. It takes the values from the first column (index 0) of the DataFrame.\n",
    "\n",
    "# y = ['Accuracy', 'Precision', 'Recall', 'F1_score']: This sets the labels for each bar on the y-axis, \n",
    "#corresponding to the different metrics being visualized.\n",
    "\n",
    "# text = np.round_(show_metrics[0].values,4): This adds text labels to each bar, displaying the rounded metric values \n",
    "#(up to 4 decimal places) for better readability.\n",
    "\n",
    "# textposition = 'auto': This automatically positions the text labels within the bars for optimal visibility.\n",
    "\n",
    "# orientation = 'h': This sets the orientation of the bars to horizontal, meaning the bars will extend horizontally \n",
    "#from the y-axis.\n",
    "\n",
    "# opacity = 0.8: This controls the transparency of the bars, making them slightly see-through.\n",
    "    trace2 = go.Bar(x = (show_metrics[0].values),\n",
    "                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n",
    "                    textposition = 'auto',\n",
    "                   orientation = 'h', opacity = 0.8,marker=dict(\n",
    "            color=colors,\n",
    "            line=dict(color='#000000',width=1.5)))\n",
    "\n",
    "    #Roc curve\n",
    "    model_roc_auc = round(roc_auc_score(y_test, y_hat) , 3)#Calculate ROC AUC score\n",
    "    # False Positive Rate on x-axis\n",
    "    # True Positive Rate on y-axis\n",
    "    fpr, tpr, t = roc_curve(y_test, y_hat)# Calculate ROC curve values\n",
    "    # Create ROC curve trace\n",
    "    trace3 = go.Scatter(x = fpr,y = tpr,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),# Name the trace with ROC AUC score\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n",
    "                        # Fill area under the curve,# Set line color and width\n",
    "    # Create diagonal line trace (random classifier)\n",
    "    trace4 = go.Scatter(x = [0,1],y = [0,1],\n",
    "                        line = dict(color = ('black'),width = 1.5,\n",
    "                        dash = 'dot'))\n",
    "\n",
    "    # Precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_hat)\n",
    "    trace5 = go.Scatter(x = recall, y = precision,\n",
    "                        name = \"Precision\" + str(precision),\n",
    "                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n",
    "\n",
    "\n",
    "    #plots\n",
    "    model = model\n",
    "\n",
    "    #Subplots\n",
    "    #This function from the Plotly Tools library is used to create a figure with multiple subplots.\n",
    "    # specs=[\n",
    "#     [{}, {}],\n",
    "#     [{}, {}],\n",
    "# ]: This argument defines the layout and structure of the subplots within the grid. \n",
    "#Each inner list represents a row, and each dictionary within a list represents a subplot\n",
    "    fig = tls.make_subplots(rows=2, cols=2, print_grid=False,\n",
    "                          specs=[\n",
    "#                               [{'colspan': 2}, None],\n",
    "                                 [{}, {}],\n",
    "                                 [{}, {}],\n",
    "\n",
    "#                                  [{'colspan': 2}, None]\n",
    "                                ],\n",
    "                            # subplot_titles=('Confusion Matrix', ...): Provides titles for each subplot. \n",
    "                            #In this case, the first subplot is titled 'Confusion Matrix', \n",
    "                            #and the titles for the remaining subplots would be specified in the subsequent positions.\n",
    "                          subplot_titles=('Confusion Matrix',\n",
    "                                        'Metrics',\n",
    "                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n",
    "                                        'Precision - Recall curve',\n",
    "                                        ))\n",
    "\n",
    "    fig.append_trace(trace1,1,1)\n",
    "    fig.append_trace(trace2,1,2)\n",
    "    fig.append_trace(trace3,2,1)\n",
    "    fig.append_trace(trace4,2,1)\n",
    "    fig.append_trace(trace5,2,2)\n",
    "\n",
    "    fig['layout'].update(showlegend = False, title = '<b>Model performance report</b><br>'+str(model),\n",
    "                        autosize = False, height = 1500,width = 830,\n",
    "                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        margin = dict(b = 195))\n",
    "    fig.layout.titlefont.size = 14\n",
    "\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b9b125",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "\n",
    "\n",
    "### Parameter tuning, also known as hyperparameter optimization, is crucial in machine learning for several reasons:\n",
    "\n",
    "###  1. Performance Optimization: \n",
    "#####     - Machine learning models have hyperparameters that control their learning process and complexity. \n",
    "#####     - Proper tuning finds the optimal combination of these hyperparameters, leading to significant improvements in model performance (accuracy, precision, recall, etc.).\n",
    "\n",
    "###  2. Generalization: \n",
    "#####    - Overly complex models can overfit the training data, performing well on seen data but poorly on new, unseen data. \n",
    "#####   - Parameter tuning helps find the right balance between model complexity and generalization, ensuring the model performs well on both training and unseen data.\n",
    "\n",
    "###  3. Efficiency: \n",
    "#####     - Some hyperparameters affect the computational cost of training and prediction. \n",
    "#####     - Tuning can help find efficient settings that reduce training time and resource usage without sacrificing performance.\n",
    "\n",
    "###  4. Robustness: \n",
    "#####    - Different datasets and problem domains may require different hyperparameter settings. \n",
    "#####     - Tuning ensures the model is robust and adaptable to various scenarios.\n",
    "\n",
    "#####  In the provided code, GridSearchCV is used for parameter tuning:\n",
    "\n",
    "##### - It systematically explores a defined hyperparameter grid (params).\n",
    "#####  - It evaluates model performance using cross-validation (gkf) and the chosen metric (AUC).\n",
    "#####  - It identifies the best hyperparameter combination (gsearch.best_params_) that maximizes performance.\n",
    "\n",
    "#####  By investing time in parameter tuning, you can unlock the full potential of your machine learning models, achieving better accuracy, generalization, and efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de4c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold: This is a cross-validation technique used to split the training data into multiple folds (subsets).\n",
    "# n_splits=3: Specifies that the data will be divided into 3 folds.\n",
    "# shuffle=True: Indicates that the data will be shuffled randomly before splitting. This helps ensure that the folds are representative of the overall data distribution.\n",
    "# random_state=42: Sets a seed for the random number generator, ensuring reproducibility of the splits.\n",
    "# .split(X=X_train, y=y_train): Applies the KFold splitting strategy to the training data (X_train and y_train).\n",
    "#The resulting 'gkf' object can be used to iterate through the different folds during model training and evaluation.\n",
    "gkf = KFold(n_splits=3, shuffle=True, random_state=42).split(X=X_train, y=y_train)\n",
    "# fit_params_of_xgb: This dictionary contains parameters that control the training process of the XGBoost model.\n",
    "# early_stopping_rounds=100: Specifies that training will stop if the model's performance on the evaluation \n",
    "#set doesn't improve for 100 consecutive rounds. This helps prevent overfitting.\n",
    "# eval_metric='auc': Sets the evaluation metric to be the Area Under the Receiver Operating Characteristic Curve (AUC), \n",
    "#a common metric for binary classification problems.\n",
    "# eval_set=[(X_test, y_test)]: Specifies the test data (X_test and y_test) as \n",
    "#the evaluation set to monitor performance during training.\n",
    "# verbose=100: Controls the level of verbosity during training, printing progress updates every 100 rounds.\n",
    "fit_params_of_xgb = {\n",
    "    \"early_stopping_rounds\":100,\n",
    "    \"eval_metric\" : 'auc',\n",
    "    \"eval_set\" : [(X_test, y_test)],\n",
    "    'verbose': 100,\n",
    "}\n",
    "\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "# booster=[\"gbtree\"]: Sets the booster type to \"gbtree\", which is the gradient boosting tree algorithm.\n",
    "# learning_rate=[0.1]: Specifies the learning rate, controlling the step size at each iteration of boosting.\n",
    "# n_estimators=range(100, 500, 100): Defines the range of number of estimators (trees) to try, \n",
    "#from 100 to 500 with a step of 100.\n",
    "# min_child_weight=[1, ...]: Specifies the minimum sum of instance weight (hessian) needed in a child node. \n",
    "#This parameter controls the complexity of individual trees.\n",
    "params = {\n",
    "    'booster': [\"gbtree\"],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': range(100, 500, 100),\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'max_depth': [5],\n",
    "    \"scale_pos_weight\": [1]\n",
    "}\n",
    "# **XGBoost Model Training and Hyperparameter Tuning**\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_estimator = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    # silent=True,\n",
    ")\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=xgb_estimator, # The XGBoost model to tune\n",
    "    param_grid=params,# The hyperparameter grid to search over\n",
    "    scoring='roc_auc',#Use AUC as the evaluation metric\n",
    "    n_jobs=-1,# Use all available CPU cores for parallel processing\n",
    "    cv=gkf# Use the defined KFold cross-validation strategy\n",
    ")\n",
    "\n",
    "xgb_model = gsearch.fit(X=X_train, y=y_train, **fit_params_of_xgb)\n",
    "(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d703e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBClassifier(n_estimators=3000,\n",
    "    objective='binary:logistic',\n",
    "    booster=\"gbtree\",\n",
    "    learning_rate=0.01,\n",
    "    scale_pos_weight=1,\n",
    "    max_depth=4,\n",
    "    min_child_weight=6,\n",
    "    gamma=0,\n",
    "    subsample=0.4,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.08,\n",
    "    n_jobs=-1)\n",
    "\n",
    "xgb_tuned.fit(X_train._get_numeric_data(), np.ravel(y_train, order='C'))\n",
    "y__hat = xgb_tuned.predict(X_test._get_numeric_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance(xgb_tuned,y_test, y__hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8705fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y__hat[21:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b094043",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sample = X_test.sample(2500)\n",
    "X_test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c545f",
   "metadata": {},
   "source": [
    "###### SHAP is a game theoretic approach to explain the output of any machine learning model.\n",
    "###### SHAP can be applied to any machine learning model, regardless of its complexity or structure.\n",
    "###### It provides individual explanations for each prediction, highlighting the contribution of each feature to that specific prediction.\n",
    "###### By aggregating local explanations, SHAP can provide insights into the overall behavior of the model and identify important features.\n",
    "###### SHAP values can be used to determine the relative importance of different features in the model's predictions.\n",
    "###### SHAP offers various visualization tools to help interpret the model's behavior and understand the impact of individual features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03567982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'xgb_tuned' is your trained XGBoost model and 'X_test_sample' is a sample of your test data\n",
    "# Create a TreeExplainer object\n",
    "# Calculate SHAP values for the test sample\n",
    "# 'shap_values' now contains the SHAP values for each feature and instance in 'X_test_sample'.\n",
    "# These values represent the contribution of each feature to the model's prediction for each instance.\n",
    "# - Summary plot to visualize feature importance and impact:\n",
    "shap_values = shap.TreeExplainer(xgb_tuned).shap_values(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c915b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_sample, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc971b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first prediction's explanation with a force plot\n",
    "\n",
    "# - Force plot to explain individual predictions:\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[0,:], X_test_sample.iloc[0,:])\n",
    "\n",
    "# Visualize the first 257 predictions' explanations with a force plot\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[0:257,:], X_test_sample.iloc[0:257,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffe760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y__hat[50])\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[50], X_test_sample.iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94771e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y__hat[21])\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[21], X_test_sample.iloc[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y__hat[23])\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[23], X_test_sample.iloc[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y__hat[60])\n",
    "shap.force_plot(shap.TreeExplainer(xgb_tuned).expected_value, shap_values[60], X_test_sample.iloc[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Dependence plots to show the relationship between feature values and SHAP values:\n",
    "shap.dependence_plot('apache_4a_icu_death_prob', shap_values, X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns in X_test_sample\n",
    "non_numeric_cols = X_test_sample.select_dtypes(exclude=['number']).columns\n",
    "print(non_numeric_cols)\n",
    "\n",
    "# Convert non-numeric columns to numeric if appropriate\n",
    "# For example, if a column contains strings that represent numbers,\n",
    "# you can use the to_numeric() function:\n",
    "# X_test_sample['column_name'] = pd.to_numeric(X_test_sample['column_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric columns to numeric if appropriate\n",
    "for col in X_test_sample.select_dtypes(include=['object']):\n",
    "    try:\n",
    "        X_test_sample[col] = pd.to_numeric(X_test_sample[col], errors='coerce')\n",
    "        # 'coerce' will replace non-convertible values with NaN\n",
    "    except:\n",
    "        print(f\"Could not convert column {col} to numeric.\")\n",
    "\n",
    "# Fill any missing values (NaN) with a suitable strategy, like the median:\n",
    "X_test_sample = X_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.decision_plot: This function from the SHAP library creates a decision plot that visualizes the decision path \n",
    "#taken by the model for specific instances.\n",
    "# By analyzing the decision plot, you can gain insights into how the model arrived at its predictions for the selected \n",
    "#instances. You can identify the key features that influenced the decisions and understand the direction and \n",
    "#magnitude of their impact.\n",
    "# feature_names=X_test_sample.columns.tolist(): This provides the names of the features, which will be displayed on the plot \n",
    "#to identify the contributing factors.\n",
    "# shap_values[110:130]: This selects a subset of SHAP values for instances 110 to 130 from the test sample. \n",
    "#These values represent the contribution of each feature to the model's prediction for these specific instances.\n",
    "# shap.TreeExplainer(xgb_tuned).expected_value[0]: This provides the base value or expected prediction of the model, \n",
    "#typically the average prediction over the training data. It serves as the starting point for the decision path.\n",
    "explainer = shap.TreeExplainer(xgb_tuned)\n",
    "shap_values = explainer.shap_values(X_test_sample.iloc[110:130])  # Get SHAP values for the specified range of samples\n",
    "\n",
    "shap.decision_plot(explainer.expected_value,\n",
    "                   shap_values,\n",
    "                   feature_names=X_test_sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ac3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
